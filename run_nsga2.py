"""
NSGA-IIå¤šç›®æ ‡ä¼˜åŒ–ä¸»æ‰§è¡Œè„šæœ¬
åŠŸèƒ½: ä½¿ç”¨NSGA-IIç®—æ³•åŒæ—¶ä¼˜åŒ–æ‹–æœŸã€åˆ©ç”¨ç‡å’ŒMakespanä¸‰ä¸ªç›®æ ‡
ç”Ÿæˆå¸•ç´¯æ‰˜å‰æ²¿å¹¶åˆ†ææœ€ä¼˜è§£é›†
"""

import numpy as np
import time
import pandas as pd
import matplotlib.pyplot as plt
import random
from deap import algorithms, base, creator, tools
from data_preprocessor import DataPreprocessor
from ffs_simulator import FFSSimulator
from visualize import export_results


# å…¨å±€å˜é‡å­˜å‚¨ä»¿çœŸå™¨
simulator = None

def evaluate_individual(individual):
    """è¯„ä¼°ä¸ªä½“çš„å¤šç›®æ ‡é€‚åº”åº¦"""
    solution = np.array(individual)
    objectives = simulator.pareto_fitness(solution)
    return objectives


def run_nsga2_optimization():
    """è¿è¡ŒNSGA-IIå¤šç›®æ ‡ä¼˜åŒ–"""
    global simulator
    
    print("ğŸš€ å¼€å§‹NSGA-IIå¤šç›®æ ‡ä¼˜åŒ–...")
    start_time = time.time()
    
    # ========== æ­¥éª¤1: æ•°æ®é¢„å¤„ç† ==========
    print("\nğŸ“Š åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
    preprocessor = DataPreprocessor(
        orders_file='è®¢å•æ•°æ®.csv',
        process_times_file='å·¥åºåŠ å·¥æ—¶é—´.csv',
        machines_file='è®¾å¤‡å¯ç”¨æ—¶é—´.csv'
    )
    data = preprocessor.process()
    
    # ========== æ­¥éª¤2: åˆ›å»ºä»¿çœŸå™¨ ==========
    print("ğŸ¯ åˆ›å»ºFFSä»¿çœŸå™¨...")
    simulator = FFSSimulator(data)
    
    # ========== æ­¥éª¤3: é…ç½®DEAPæ¡†æ¶ ==========
    print("âš™ï¸ é…ç½®DEAP NSGA-IIæ¡†æ¶...")
    
    # æŸ“è‰²ä½“ç»´åº¦
    total_ops = data['num_orders'] * data['num_stages']
    CHROMOSOME_LENGTH = total_ops * 2  # OS + MS
    
    # åˆ›å»ºé€‚åº”åº¦ç±»å’Œä¸ªä½“ç±»
    creator.create("FitnessMulti", base.Fitness, weights=(-1.0, 1.0, -1.0))  # æœ€å°åŒ–æ‹–æœŸï¼Œæœ€å¤§åŒ–åˆ©ç”¨ç‡ï¼Œæœ€å°åŒ–makespan
    creator.create("Individual", list, fitness=creator.FitnessMulti)
    
    # åˆ›å»ºå·¥å…·ç®±
    toolbox = base.Toolbox()
    
    # æ³¨å†ŒåŸºå› ç”Ÿæˆå‡½æ•°
    toolbox.register("attr_float", random.uniform, 0.0, 0.9999)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, CHROMOSOME_LENGTH)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    
    # æ³¨å†Œé—ä¼ æ“ä½œ
    toolbox.register("evaluate", evaluate_individual)
    toolbox.register("mate", tools.cxSimulatedBinaryBounded, low=0.0, up=0.9999, eta=20.0)
    toolbox.register("mutate", tools.mutPolynomialBounded, low=0.0, up=0.9999, eta=20.0, indpb=1.0/CHROMOSOME_LENGTH)
    toolbox.register("select", tools.selNSGA2)
    
    # ========== æ­¥éª¤4: è¿è¡ŒNSGA-IIä¼˜åŒ– ==========
    print("ğŸ”„ å¼€å§‹NSGA-IIä¼˜åŒ–...")
    
    # å‚æ•°è®¾ç½®
    POPULATION_SIZE = 80
    GENERATIONS = 200
    CROSSOVER_PROB = 0.9
    MUTATION_PROB = 0.1
    
    print(f"  - ç›®æ ‡å‡½æ•°: [æ‹–æœŸ+æƒ©ç½š, -åˆ©ç”¨ç‡, Makespan]")
    print(f"  - ç§ç¾¤å¤§å°: {POPULATION_SIZE}")
    print(f"  - è¿­ä»£æ¬¡æ•°: {GENERATIONS}")
    print(f"  - äº¤å‰æ¦‚ç‡: {CROSSOVER_PROB}")
    print(f"  - å˜å¼‚æ¦‚ç‡: {MUTATION_PROB}")
    
    # åˆ›å»ºåˆå§‹ç§ç¾¤
    population = toolbox.population(n=POPULATION_SIZE)
    
    # è¯„ä¼°åˆå§‹ç§ç¾¤
    fitnesses = list(map(toolbox.evaluate, population))
    for ind, fit in zip(population, fitnesses):
        ind.fitness.values = fit
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = tools.Statistics(lambda ind: ind.fitness.values)
    stats.register("avg", np.mean, axis=0)
    stats.register("min", np.min, axis=0)
    stats.register("max", np.max, axis=0)
    
    # è¿è¡ŒNSGA-IIç®—æ³•
    population, logbook = algorithms.eaMuPlusLambda(
        population, toolbox, mu=POPULATION_SIZE, lambda_=POPULATION_SIZE,
        cxpb=CROSSOVER_PROB, mutpb=MUTATION_PROB, ngen=GENERATIONS,
        stats=stats, verbose=True
    )
    
    optimization_time = time.time() - start_time
    print(f"\nâœ… NSGA-IIä¼˜åŒ–å®Œæˆ! è€—æ—¶: {optimization_time:.2f}ç§’")
    
    # ========== æ­¥éª¤5: è·å–å¸•ç´¯æ‰˜å‰æ²¿ ==========
    print("\nğŸ“ˆ åˆ†æå¸•ç´¯æ‰˜å‰æ²¿...")
    
    # è·å–å¸•ç´¯æ‰˜å‰æ²¿
    pareto_front = tools.sortNondominated(population, len(population), first_front_only=True)[0]
    
    pareto_solutions = [list(ind) for ind in pareto_front]
    pareto_objectives = [ind.fitness.values for ind in pareto_front]
    pareto_objectives = np.array(pareto_objectives)
    
    print(f"å¸•ç´¯æ‰˜å‰æ²¿åŒ…å« {len(pareto_solutions)} ä¸ªè§£")
    print(f"ç›®æ ‡å‡½æ•°èŒƒå›´:")
    print(f"  - æ‹–æœŸ+æƒ©ç½š: [{pareto_objectives[:, 0].min():.2f}, {pareto_objectives[:, 0].max():.2f}]")
    print(f"  - åˆ©ç”¨ç‡: [{pareto_objectives[:, 1].min():.3f}, {pareto_objectives[:, 1].max():.3f}]")  # æ³¨æ„DEAPä¸­åˆ©ç”¨ç‡å·²ç»æ˜¯æ­£å€¼
    print(f"  - Makespan: [{pareto_objectives[:, 2].min():.2f}, {pareto_objectives[:, 2].max():.2f}]å¤©")
    
    # ========== æ­¥éª¤6: é€‰æ‹©ä»£è¡¨æ€§è§£ ==========
    print("\nğŸ¯ é€‰æ‹©ä»£è¡¨æ€§è§£...")
    
    # è§£1: æœ€å°æ‹–æœŸè§£
    min_tardiness_idx = np.argmin(pareto_objectives[:, 0])
    min_tardiness_solution = pareto_solutions[min_tardiness_idx]
    min_tardiness_obj = pareto_objectives[min_tardiness_idx]
    
    # è§£2: æœ€å¤§åˆ©ç”¨ç‡è§£
    max_utilization_idx = np.argmax(pareto_objectives[:, 1])  # DEAPä¸­åˆ©ç”¨ç‡æ˜¯æ­£å€¼ï¼Œå–æœ€å¤§
    max_utilization_solution = pareto_solutions[max_utilization_idx]
    max_utilization_obj = pareto_objectives[max_utilization_idx]
    
    # è§£3: æœ€å°Makespanè§£
    min_makespan_idx = np.argmin(pareto_objectives[:, 2])
    min_makespan_solution = pareto_solutions[min_makespan_idx]
    min_makespan_obj = pareto_objectives[min_makespan_idx]
    
    # è§£4: å¹³è¡¡è§£(ä½¿ç”¨åŠ æƒå’Œæ–¹æ³•)
    # æ ‡å‡†åŒ–ç›®æ ‡å‡½æ•°
    obj_normalized = pareto_objectives.copy()
    for i in range(3):
        obj_min = pareto_objectives[:, i].min()
        obj_max = pareto_objectives[:, i].max()
        if obj_max > obj_min:
            if i == 1:  # åˆ©ç”¨ç‡ç›®æ ‡ï¼Œè¶Šå¤§è¶Šå¥½
                obj_normalized[:, i] = (obj_max - pareto_objectives[:, i]) / (obj_max - obj_min)
            else:  # æ‹–æœŸå’Œmakespanï¼Œè¶Šå°è¶Šå¥½
                obj_normalized[:, i] = (pareto_objectives[:, i] - obj_min) / (obj_max - obj_min)
    
    # è®¡ç®—åŠ æƒå’Œ(ç­‰æƒé‡)
    weighted_sum = np.sum(obj_normalized, axis=1)
    balanced_idx = np.argmin(weighted_sum)
    balanced_solution = pareto_solutions[balanced_idx]
    balanced_obj = pareto_objectives[balanced_idx]
    
    # ========== æ­¥éª¤7: è¯¦ç»†è¯„ä¼°ä»£è¡¨æ€§è§£ ==========
    print("\nğŸ“Š è¯¦ç»†è¯„ä¼°ä»£è¡¨æ€§è§£...")
    
    solutions_to_evaluate = [
        ("æœ€å°æ‹–æœŸè§£", min_tardiness_solution, min_tardiness_obj),
        ("æœ€å¤§åˆ©ç”¨ç‡è§£", max_utilization_solution, max_utilization_obj),
        ("æœ€å°Makespanè§£", min_makespan_solution, min_makespan_obj),
        ("å¹³è¡¡è§£", balanced_solution, balanced_obj)
    ]
    
    results = {}
    
    for name, solution, objectives in solutions_to_evaluate:
        print(f"\n--- {name} ---")
        print(f"ç›®æ ‡å‡½æ•°å€¼: æ‹–æœŸ={objectives[0]:.2f}, åˆ©ç”¨ç‡={objectives[1]:.3f}, Makespan={objectives[2]:.2f}å¤©")
        
        # è¯¦ç»†è¯„ä¼°
        result = simulator.evaluate_solution(solution)
        results[name] = result
        
        # è¾“å‡ºKPI
        kpis = result['kpis']
        print(f"KPIæŒ‡æ ‡:")
        print(f"  - æ€»åŠ æƒæ‹–æœŸ: {kpis['total_weighted_tardiness']:.2f}å¤©")
        print(f"  - è®¢å•å‡†æ—¶äº¤ä»˜ç‡: {kpis['on_time_delivery_rate']:.1f}%")
        print(f"  - å¹³å‡æ‹–æœŸ: {kpis['avg_tardiness']:.2f}å¤©")
        print(f"  - Makespan: {kpis['makespan_days']:.2f}å¤©")
        print(f"  - è®¾å¤‡å¹³å‡åˆ©ç”¨ç‡: {kpis['avg_utilization']:.2f}%")
        print(f"  - ç“¶é¢ˆè®¾å¤‡è´Ÿè½½ç‡: {kpis['bottleneck_load']:.2f}%")
        print(f"  - è´Ÿè½½å‡è¡¡åº¦: {kpis['load_balance_std']:.2f}%")
    
    # ========== æ­¥éª¤8: å¯¼å‡ºç»“æœ ==========
    print("\nğŸ’¾ å¯¼å‡ºç»“æœ...")
    
    # é€‰æ‹©å¹³è¡¡è§£ä½œä¸ºæœ€ç»ˆè§£è¿›è¡Œå¯¼å‡º
    final_result = results["å¹³è¡¡è§£"]
    
    # å¯¼å‡ºè°ƒåº¦ç»“æœ
    export_results(
        final_result['completion_times'],
        final_result['schedule'],
        final_result['kpis'],
        data,
        algorithm="NSGA2"
    )
    
    # ä¿å­˜å¸•ç´¯æ‰˜å‰æ²¿æ•°æ®
    pareto_df = pd.DataFrame(pareto_objectives, columns=['Tardiness_Penalty', 'Neg_Utilization', 'Makespan'])
    pareto_df['Utilization'] = -pareto_df['Neg_Utilization']
    pareto_df.drop('Neg_Utilization', axis=1, inplace=True)
    pareto_df.to_csv('pareto_front_NSGA2.csv', index=False)
    
    # ä¿å­˜ä»£è¡¨æ€§è§£çš„KPIå¯¹æ¯”
    comparison_data = []
    for name, result in results.items():
        kpis = result['kpis']
        comparison_data.append({
            'Solution': name,
            'Total_Weighted_Tardiness': kpis['total_weighted_tardiness'],
            'On_Time_Delivery_Rate': kpis['on_time_delivery_rate'],
            'Avg_Tardiness': kpis['avg_tardiness'],
            'Makespan_Days': kpis['makespan_days'],
            'Avg_Utilization': kpis['avg_utilization'],
            'Bottleneck_Load': kpis['bottleneck_load'],
            'Load_Balance_Std': kpis['load_balance_std']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_df.to_csv('nsga2_solutions_comparison.csv', index=False)
    
    print(f"âœ… ç»“æœå·²å¯¼å‡º:")
    print(f"  - å¸•ç´¯æ‰˜å‰æ²¿: pareto_front_NSGA2.csv")
    print(f"  - è§£é›†å¯¹æ¯”: nsga2_solutions_comparison.csv")
    print(f"  - è°ƒåº¦ç»“æœ: schedule_orders_NSGA2.csv, schedule_kpis_NSGA2.csv")
    print(f"  - ç”˜ç‰¹å›¾: schedule_gantt_NSGA2.html")
    
    return results, pareto_objectives, pareto_solutions


if __name__ == "__main__":
    try:
        results, pareto_front, pareto_solutions = run_nsga2_optimization()
        print("\nğŸ‰ NSGA-IIå¤šç›®æ ‡ä¼˜åŒ–æˆåŠŸå®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ NSGA-IIä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()